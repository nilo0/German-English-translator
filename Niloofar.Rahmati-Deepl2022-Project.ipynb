{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d840f4-28ac-47c9-86d7-abbfed6dae81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparision of coustume LSTM model, state of the art MarianMT  \n",
    "\n",
    "\n",
    "In this notebook, we compare the performance of a customized LSTM translator model with the state of the art pre-trained model loaded from the hugging face and fine-tuned on our dataset. Taking advantage from the Anki dataset, we train the customized LSTM translator and fine tune the\n",
    "\n",
    "\"Helsinki-NLP/opus-mt-de-en\" model  which is a pre-trained neural machine translation (NMT) model that is part of the Opus-MT project, which provides a collection of pre-trained machine translation models for multiple language pairs.\n",
    "\n",
    "As the \"de-en\" in the model name indicates that it is a model trained to translate from German (de) to English (en). The model is based on a transformer architecture and was trained on a large corpus of German and English text using the open-source Hugging Face Transformers library.\n",
    "\n",
    "\n",
    "To evaluate the performance of both models, we use the\n",
    "\n",
    "'sentence_bleu' which is a function from the Natural Language Toolkit package that computes the sentence-level BLEU score between a candidate sentence and a set of reference sentences. BLEU is a popular way to measure the quality of machine translation output.\n",
    "\n",
    "The BLEU score measures the degree of similarity between the candidate sentence and one or more reference sentences based on their n-gram overlap. The function computes the BLEU score for a single candidate sentence and a reference sentence.\n",
    "\n",
    "We train both models on the 5000 sentence pairs from the de-en Anki dataset in order to obtain short running time for executing the codes in this notebook. However this results in very low performance of our custumized LSTM translator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf1802-d497-4bf3-9a0d-441f1d80eca8",
   "metadata": {},
   "source": [
    "## Import the packages and seting constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d9a67c5-1666-4739-9c20-f3f21ed1e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector, SimpleRNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac358617-860c-4555-bb43-b1cfcc36f19c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading, preprocessing, and splitting the data into train, test and validation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90b05be9-7316-4705-88d1-e539b6eff6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English-German sentence pairs from anki dataset, shuffle and load the 5000 rows to train, test and validate the models\n",
    "#update the path if necessary\n",
    "path = \"../Translator/deu-eng/deu.txt\"\n",
    "sentence_pairs = pd.read_csv(path ,sep='\\t',names=[\"en\", \"de\", \"Remark\"]).drop('Remark', axis=1).sample(frac=1, random_state=123).iloc[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3855dcc-717b-4307-8ea5-fd9f11d66642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176581</th>\n",
       "      <td>i wont be at the opening ceremony</td>\n",
       "      <td>ich werde an der eröffnungszeremonie nicht tei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228059</th>\n",
       "      <td>tom didnt want mary to babysit his children</td>\n",
       "      <td>tom wollte nicht dass maria auf seine kinder a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175992</th>\n",
       "      <td>i havent given it any thought yet</td>\n",
       "      <td>darüber habe ich mir noch keine gedanken gemacht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224728</th>\n",
       "      <td>tom and mary admired the landscape together</td>\n",
       "      <td>tom und maria bewunderten zusammen die landschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85804</th>\n",
       "      <td>ill do whatever you ask</td>\n",
       "      <td>ich werde alles tun was du verlangst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 en  \\\n",
       "176581            i wont be at the opening ceremony   \n",
       "228059  tom didnt want mary to babysit his children   \n",
       "175992            i havent given it any thought yet   \n",
       "224728  tom and mary admired the landscape together   \n",
       "85804                       ill do whatever you ask   \n",
       "\n",
       "                                                       de  \n",
       "176581  ich werde an der eröffnungszeremonie nicht tei...  \n",
       "228059  tom wollte nicht dass maria auf seine kinder a...  \n",
       "175992   darüber habe ich mir noch keine gedanken gemacht  \n",
       "224728  tom und maria bewunderten zusammen die landschaft  \n",
       "85804                ich werde alles tun was du verlangst  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove special characters and punctuation and transform sentences into lower case\n",
    "sentence_pairs[\"en\"] = sentence_pairs['en'].str.lower().replace('[^\\w\\s]','', regex = True)\n",
    "sentence_pairs[\"de\"] = sentence_pairs['de'].str.lower().replace('[^\\w\\s]','', regex = True)\n",
    "\n",
    "sentence_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "891c8bf8-1961-4cd0-9565-c6674d5b2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 4000\n",
      "500 500\n",
      "500 500\n"
     ]
    }
   ],
   "source": [
    "# Split data into train validation and test \n",
    "train_size = int(len(sentence_pairs) * 0.8)\n",
    "test_val_size =  int(len(sentence_pairs) * 0.1)\n",
    "\n",
    "df_train = sentence_pairs.iloc[: train_size]\n",
    "df_val = sentence_pairs.iloc[train_size: train_size+test_val_size]\n",
    "df_test = sentence_pairs.iloc[train_size+test_val_size : ]\n",
    "\n",
    "# Convert train, test, validation of English and German to list\n",
    "en_train, de_train = df_train[\"en\"], df_train[\"de\"]\n",
    "en_val, de_val = df_val[\"en\"], df_val[\"de\"]\n",
    "en_test, de_test = df_test[\"en\"], df_test[\"de\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e01c3-8a4b-4220-b743-9105403a191c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Customized LSTM translator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dec844b-871e-446f-8a0e-d7aa3826ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# create tokenizer for English and fit on sentence_pairs[\"en\"]\n",
    "en_tokenizer = Tokenizer()\n",
    "en_tokenizer.fit_on_texts(sentence_pairs[\"en\"])\n",
    "\n",
    "#create tokenizer for German and fit on sentence_pairs[\"de\"]\n",
    "de_tokenizer = Tokenizer()\n",
    "de_tokenizer.fit_on_texts(sentence_pairs[\"de\"])\n",
    "\n",
    "#get the number of unique English and German words\n",
    "en_words = len(en_tokenizer.word_index) + 1\n",
    "de_words = len(de_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49405c16-1536-44be-8c19-b0e75fc071c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert senteces to vectors\n",
    "def convert_to_vectors(tokenizer, max_length, sents):\n",
    "    sequences = tokenizer.texts_to_sequences(sents)\n",
    "    text = pad_sequences(sequences, maxlen=max_length)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa7abbf8-975e-4a24-bf95-27f455c12106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 27\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "#maximum sequence size - English\n",
    "max_len_en = max([len(text_to_word_sequence(x)) for x in sentence_pairs[\"en\"]])\n",
    "\n",
    "#maximum sequence size - German\n",
    "max_len_de = max([len(text_to_word_sequence(x)) for x in sentence_pairs[\"de\"]])\n",
    "\n",
    "print(max_len_en, max_len_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e203dd9-e5d6-4b4a-84d4-f986041ac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert English and German training and test data to vectors\n",
    "en_train_vec = convert_to_vectors(en_tokenizer, max_len_en, en_train).astype(\"float32\")\n",
    "de_train_vec = convert_to_vectors(de_tokenizer, max_len_de, de_train).astype(\"float32\")\n",
    "\n",
    "\n",
    "en_test_vec = convert_to_vectors(en_tokenizer, max_len_en, en_test).astype(\"float32\")\n",
    "de_test_vec = convert_to_vectors(de_tokenizer, max_len_de, de_test).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31b024c8-1750-44f4-90bc-d16267bed823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "in_vocab = de_words # German vocab size \n",
    "out_vocab = en_words # English vocab size\n",
    "in_timesteps = max_len_de # Length of the input sequence  \n",
    "out_timesteps = max_len_en # Length of the output sequence\n",
    "learning_rate = 0.001 # Learning rate\n",
    "epochs = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb77047d-b90b-4fa1-80bc-b5c11320fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 27, 512)           2463232   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 23, 512)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 23, 512)           2099200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 23, 3414)          1751382   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,413,014\n",
      "Trainable params: 8,413,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(in_vocab, 512, input_length=in_timesteps, mask_zero=True))\n",
    "lstm_model.add(LSTM(512, go_backwards = True)) \n",
    "lstm_model.add(RepeatVector(out_timesteps))\n",
    "lstm_model.add(LSTM(512, return_sequences=True))\n",
    "lstm_model.add(Dense(out_vocab, activation=\"softmax\"))\n",
    "\n",
    "#compile the model with optimizer, loss function, and metrics               \n",
    "adam = optimizers.Adam(learning_rate=learning_rate)\n",
    "lstm_model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da64d866-4602-4730-8f74-5d10ab510a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "8/8 [==============================] - 34s 3s/step - loss: 6.8983 - accuracy: 0.6327 - val_loss: 3.3337 - val_accuracy: 0.7208\n",
      "Epoch 2/32\n",
      "8/8 [==============================] - 20s 2s/step - loss: 2.7863 - accuracy: 0.7252 - val_loss: 2.5754 - val_accuracy: 0.7208\n",
      "Epoch 3/32\n",
      "8/8 [==============================] - 20s 2s/step - loss: 2.4180 - accuracy: 0.7252 - val_loss: 2.4564 - val_accuracy: 0.7208\n",
      "Epoch 4/32\n",
      "8/8 [==============================] - 20s 2s/step - loss: 2.3349 - accuracy: 0.7252 - val_loss: 2.4026 - val_accuracy: 0.7208\n",
      "Epoch 5/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.3009 - accuracy: 0.7252 - val_loss: 2.3881 - val_accuracy: 0.7208\n",
      "Epoch 6/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.2787 - accuracy: 0.7252 - val_loss: 2.3670 - val_accuracy: 0.7208\n",
      "Epoch 7/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2.2561 - accuracy: 0.7249 - val_loss: 2.3455 - val_accuracy: 0.7208\n",
      "Epoch 8/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.2289 - accuracy: 0.7249 - val_loss: 2.3187 - val_accuracy: 0.7208\n",
      "Epoch 9/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.1965 - accuracy: 0.7249 - val_loss: 2.2881 - val_accuracy: 0.7208\n",
      "Epoch 10/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2.1639 - accuracy: 0.7249 - val_loss: 2.2636 - val_accuracy: 0.7208\n",
      "Epoch 11/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2.1325 - accuracy: 0.7249 - val_loss: 2.2228 - val_accuracy: 0.7208\n",
      "Epoch 12/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.0927 - accuracy: 0.7249 - val_loss: 2.1912 - val_accuracy: 0.7208\n",
      "Epoch 13/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2.0738 - accuracy: 0.7249 - val_loss: 2.2232 - val_accuracy: 0.7208\n",
      "Epoch 14/32\n",
      "8/8 [==============================] - 20s 3s/step - loss: 2.0548 - accuracy: 0.7247 - val_loss: 2.1591 - val_accuracy: 0.7208\n",
      "Epoch 15/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 2.0123 - accuracy: 0.7244 - val_loss: 2.1360 - val_accuracy: 0.7208\n",
      "Epoch 16/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9733 - accuracy: 0.7244 - val_loss: 2.0728 - val_accuracy: 0.7208\n",
      "Epoch 17/32\n",
      "8/8 [==============================] - 22s 3s/step - loss: 1.9350 - accuracy: 0.7242 - val_loss: 2.1027 - val_accuracy: 0.7208\n",
      "Epoch 18/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9809 - accuracy: 0.7240 - val_loss: 2.0505 - val_accuracy: 0.7208\n",
      "Epoch 19/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9702 - accuracy: 0.7237 - val_loss: 2.0546 - val_accuracy: 0.7208\n",
      "Epoch 20/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9311 - accuracy: 0.7227 - val_loss: 2.0245 - val_accuracy: 0.7208\n",
      "Epoch 21/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9091 - accuracy: 0.7211 - val_loss: 2.0281 - val_accuracy: 0.7196\n",
      "Epoch 22/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9007 - accuracy: 0.7195 - val_loss: 2.0082 - val_accuracy: 0.7196\n",
      "Epoch 23/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8875 - accuracy: 0.7188 - val_loss: 2.0062 - val_accuracy: 0.7194\n",
      "Epoch 24/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8745 - accuracy: 0.7206 - val_loss: 2.0157 - val_accuracy: 0.7188\n",
      "Epoch 25/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9031 - accuracy: 0.7241 - val_loss: 2.0363 - val_accuracy: 0.7201\n",
      "Epoch 26/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.9108 - accuracy: 0.7248 - val_loss: 2.0496 - val_accuracy: 0.7190\n",
      "Epoch 27/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8749 - accuracy: 0.7258 - val_loss: 2.0802 - val_accuracy: 0.7240\n",
      "Epoch 28/32\n",
      "8/8 [==============================] - 22s 3s/step - loss: 1.8859 - accuracy: 0.7278 - val_loss: 2.0692 - val_accuracy: 0.7265\n",
      "Epoch 29/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8772 - accuracy: 0.7292 - val_loss: 2.0293 - val_accuracy: 0.7260\n",
      "Epoch 30/32\n",
      "8/8 [==============================] - 22s 3s/step - loss: 1.8562 - accuracy: 0.7301 - val_loss: 2.0178 - val_accuracy: 0.7257\n",
      "Epoch 31/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8419 - accuracy: 0.7300 - val_loss: 2.0318 - val_accuracy: 0.7254\n",
      "Epoch 32/32\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8326 - accuracy: 0.7309 - val_loss: 2.0063 - val_accuracy: 0.7272\n"
     ]
    }
   ],
   "source": [
    "#train the model on the training data and validate on the test data\n",
    "history = lstm_model.fit(de_train_vec, \n",
    "                         en_train_vec.reshape(en_train_vec.shape[0], en_train_vec.shape[1], 1),\n",
    "                         epochs=epochs, \n",
    "                         batch_size=512, #neurons\n",
    "                         validation_data=(de_test_vec, en_test_vec.reshape(en_test_vec.shape[0], en_test_vec.shape[1], 1)), \n",
    "                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca3d1667-ffa8-4637-962f-cc298ca4cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 123ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>actual</th>\n",
       "      <th>lstm_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193956</th>\n",
       "      <td>du hast es zu früh aus dem ofen geholt</td>\n",
       "      <td>you took it out of the oven too soon</td>\n",
       "      <td>to to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40774</th>\n",
       "      <td>es friert wieder</td>\n",
       "      <td>its freezing again</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214627</th>\n",
       "      <td>kinder sollten kind sein dürfen</td>\n",
       "      <td>children should be allowed to be children</td>\n",
       "      <td>to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153323</th>\n",
       "      <td>es ist offensichtlich dass tom gelogen hat</td>\n",
       "      <td>its obvious that tom was lying</td>\n",
       "      <td>to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196436</th>\n",
       "      <td>ist das ihr erster besuch dieser stadt</td>\n",
       "      <td>is this your first visit to this town</td>\n",
       "      <td>to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>ich bin beliebt</td>\n",
       "      <td>im popular</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242060</th>\n",
       "      <td>das restaurant liegt auf der dem hotel gegenüb...</td>\n",
       "      <td>the restaurant is across the street from the h...</td>\n",
       "      <td>to to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98885</th>\n",
       "      <td>tom hat seine autoschlüssel verloren</td>\n",
       "      <td>tom has lost his car keys</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175799</th>\n",
       "      <td>ich glaube nicht dass sie französisch spricht</td>\n",
       "      <td>i dont think she can speak french</td>\n",
       "      <td>to to to to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164527</th>\n",
       "      <td>tom wusste dass er unersetzbar war</td>\n",
       "      <td>tom knew he couldnt be replaced</td>\n",
       "      <td>to to to to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "193956             du hast es zu früh aus dem ofen geholt   \n",
       "40774                                    es friert wieder   \n",
       "214627                    kinder sollten kind sein dürfen   \n",
       "153323         es ist offensichtlich dass tom gelogen hat   \n",
       "196436             ist das ihr erster besuch dieser stadt   \n",
       "...                                                   ...   \n",
       "2742                                      ich bin beliebt   \n",
       "242060  das restaurant liegt auf der dem hotel gegenüb...   \n",
       "98885                tom hat seine autoschlüssel verloren   \n",
       "175799      ich glaube nicht dass sie französisch spricht   \n",
       "164527                 tom wusste dass er unersetzbar war   \n",
       "\n",
       "                                                   actual lstm_prediction  \n",
       "193956               you took it out of the oven too soon  to to to to to  \n",
       "40774                                  its freezing again                  \n",
       "214627          children should be allowed to be children        to to to  \n",
       "153323                     its obvious that tom was lying     to to to to  \n",
       "196436              is this your first visit to this town     to to to to  \n",
       "...                                                   ...             ...  \n",
       "2742                                           im popular                  \n",
       "242060  the restaurant is across the street from the h...  to to to to to  \n",
       "98885                           tom has lost his car keys                  \n",
       "175799                  i dont think she can speak french     to to to to  \n",
       "164527                    tom knew he couldnt be replaced     to to to to  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataset for comparison\n",
    "predictions = np.argmax(lstm_model.predict(de_test_vec.reshape(de_test_vec.shape[0], de_test_vec.shape[1], 1)), axis=-1)\n",
    "\n",
    "#get the predictions on the test data and convert them to texts\n",
    "lstm_prediction = en_tokenizer.sequences_to_texts(predictions)\n",
    "\n",
    "#create a dataframe with the input sentence\n",
    "result = pd.DataFrame({\"input\" : de_test, \"actual\" : en_test, \"lstm_prediction\" : lstm_prediction})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6b39c17-8f98-473a-a9b6-4421cb82e58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation and train loss per epoch\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31107097-837b-4034-90b1-a19f621a3dcd",
   "metadata": {},
   "source": [
    "After studying the loss and accuracy based on the number of epochs, we can conclude that the model does not learn well. We also observe that the predicted translation is far from the actual sentences. I should mention that this could be due to the relatively small data set we used, however, even increasing the number of sentence pairs to 50000 and 100000 did not improve the translations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b703b80-1e91-4732-ae4b-5da9eb5c2945",
   "metadata": {},
   "source": [
    "# Fine Tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48171045-b620-465a-8c05-fac164c95861",
   "metadata": {},
   "source": [
    "In order to learn how to fine tune the model loaded from the hugging face API, I have read the instructions on the hugging face website, instructions on how to fine tune a translator, and the following notebook. https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867262e2-e715-4b61-b940-ce2dbefd412b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_543020/1763702068.py:14: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_metric\n",
    "# Create a dictionary from the train, test, and validation dataframes\n",
    "# where each row is a dictionary of column names and values\n",
    "test_dict = {'translation': df_test.to_dict('records')}\n",
    "train_dict = {'translation': df_train.to_dict('records')}\n",
    "val_dict = {'translation': df_val.to_dict('records')}\n",
    "\n",
    "# Convert the dictionaries into datasets using the Hugging Face Datasets library\n",
    "dataset_train = Dataset.from_dict(train_dict)\n",
    "dataset_test = Dataset.from_dict(test_dict)\n",
    "dataset_val = Dataset.from_dict(val_dict)\n",
    "\n",
    "# Load the sacreBLEU metric for evaluation\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a7a2161-8d00-4cc1-bfdb-9b2cfa7eda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niloofar/.local/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:198: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
    "# Load the pre-trained model and tokenizer from the Hugging Face model hub\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Create a data collator that will process the data into batches for the model\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43931aa9-75e8-46fc-a9ff-91a58ca609f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum input and target sequence lengths and source/target languages\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"de\"\n",
    "target_lang = \"en\"\n",
    "\n",
    "# Define a function to preprocess the data into model inputs and labels\n",
    "def preprocessn(data):\n",
    "    inputs = [ dt[\"de\"] for dt in data[\"translation\"]]\n",
    "    targets = [df[\"en\"] for dt in data[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    \n",
    "    # Set the model inputs labels to the tokenized target sequences\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the datasets using the preprocess function and the Hugging Face Datasets library\n",
    "tokenized_datasets_train = dataset_train.map(preprocessn, batched=True)\n",
    "tokenized_datasets_test = dataset_test.map(preprocessn, batched=True)\n",
    "tokenized_datasets_val = dataset_val.map(preprocessn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ad35240-2de1-42db-bb31-a1df25b3a272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niloofar/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Set the model name and training arguments for the Seq2SeqTrainer\n",
    "model_name = 'Niloofar_Rahmati'\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=16,\n",
    "    eval_steps=16,\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12c93fa-e3d5-4845-9da3-c0b6111d62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    \n",
    "    # Compute the sacreBLEU metric\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ab6e83-44d2-4696-9847-ad4e43abc061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 17:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.701484</td>\n",
       "      <td>53.910564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>0.673973</td>\n",
       "      <td>55.509419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.666490</td>\n",
       "      <td>54.842037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.665918</td>\n",
       "      <td>55.626350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to Niloofar_Rahmati-finetuned-de-to-en/checkpoint-500\n",
      "Configuration saved in Niloofar_Rahmati-finetuned-de-to-en/checkpoint-500/config.json\n",
      "Model weights saved in Niloofar_Rahmati-finetuned-de-to-en/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in Niloofar_Rahmati-finetuned-de-to-en/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in Niloofar_Rahmati-finetuned-de-to-en/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.6284736833572387, metrics={'train_runtime': 1055.9162, 'train_samples_per_second': 15.153, 'train_steps_per_second': 0.474, 'total_flos': 79195055063040.0, 'train_loss': 0.6284736833572387, 'epoch': 4.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the fine tune model\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets_train,\n",
    "    eval_dataset=tokenized_datasets_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6db7594e-0bde-44a3-92c5-9752e8f6f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../Translator/Niloofar_Rahmati-finetuned-de-to-en/\n",
      "Configuration saved in ../Translator/Niloofar_Rahmati-finetuned-de-to-en/config.json\n",
      "Model weights saved in ../Translator/Niloofar_Rahmati-finetuned-de-to-en/pytorch_model.bin\n",
      "tokenizer config file saved in ../Translator/Niloofar_Rahmati-finetuned-de-to-en/tokenizer_config.json\n",
      "Special tokens file saved in ../Translator/Niloofar_Rahmati-finetuned-de-to-en/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "trainer.save_model(output_dir='../Translator/Niloofar_Rahmati-finetuned-de-to-en/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74611c95-9481-419a-9a8c-651026296913",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/target_vocab.json. We won't load it.\n",
      "Didn't find file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/added_tokens.json. We won't load it.\n",
      "loading file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/source.spm\n",
      "loading file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/target.spm\n",
      "loading file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/vocab.json\n",
      "loading file None\n",
      "loading file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/tokenizer_config.json\n",
      "loading file None\n",
      "loading file ../Translator/Niloofar_Rahmati-finetuned-de-to-en/special_tokens_map.json\n",
      "100%|███████████████████████████████████████| 500/500 [00:00<00:00, 4654.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load fine tuned model from local\n",
    "from tqdm import tqdm\n",
    "nil_model = AutoModelForSeq2SeqLM.from_pretrained('../Translator/Niloofar_Rahmati-finetuned-de-to-en/')\n",
    "tokenizer_niloo = AutoTokenizer.from_pretrained('../Translator/Niloofar_Rahmati-finetuned-de-to-en/')\n",
    "\n",
    "examples = de_test.to_list()\n",
    "translated = nil_model.generate(**tokenizer_trf(examples, return_tensors=\"pt\",max_length=512, padding=True, verbose=1))\n",
    "predictions_niloo = [tokenizer_niloo.decode(t, skip_special_tokens=True) for t in tqdm(translated)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "927ff6ce-043e-4dbd-a466-1c1d7016ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>actual</th>\n",
       "      <th>lstm_prediction</th>\n",
       "      <th>finetune_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193956</th>\n",
       "      <td>du hast es zu früh aus dem ofen geholt</td>\n",
       "      <td>you took it out of the oven too soon</td>\n",
       "      <td>to to to to to</td>\n",
       "      <td>you got it out of the oven too soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40774</th>\n",
       "      <td>es friert wieder</td>\n",
       "      <td>its freezing again</td>\n",
       "      <td></td>\n",
       "      <td>it freezes again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214627</th>\n",
       "      <td>kinder sollten kind sein dürfen</td>\n",
       "      <td>children should be allowed to be children</td>\n",
       "      <td>to to to</td>\n",
       "      <td>children should be allowed to be children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153323</th>\n",
       "      <td>es ist offensichtlich dass tom gelogen hat</td>\n",
       "      <td>its obvious that tom was lying</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>its obvious that tom lied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196436</th>\n",
       "      <td>ist das ihr erster besuch dieser stadt</td>\n",
       "      <td>is this your first visit to this town</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>is this your first visit to this city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>ich bin beliebt</td>\n",
       "      <td>im popular</td>\n",
       "      <td></td>\n",
       "      <td>im popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242060</th>\n",
       "      <td>das restaurant liegt auf der dem hotel gegenüb...</td>\n",
       "      <td>the restaurant is across the street from the h...</td>\n",
       "      <td>to to to to to</td>\n",
       "      <td>the restaurant is on the opposite side of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98885</th>\n",
       "      <td>tom hat seine autoschlüssel verloren</td>\n",
       "      <td>tom has lost his car keys</td>\n",
       "      <td></td>\n",
       "      <td>tom lost his car keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175799</th>\n",
       "      <td>ich glaube nicht dass sie französisch spricht</td>\n",
       "      <td>i dont think she can speak french</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>i dont think she speaks french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164527</th>\n",
       "      <td>tom wusste dass er unersetzbar war</td>\n",
       "      <td>tom knew he couldnt be replaced</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>tom knew he was irreplaceable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "193956             du hast es zu früh aus dem ofen geholt   \n",
       "40774                                    es friert wieder   \n",
       "214627                    kinder sollten kind sein dürfen   \n",
       "153323         es ist offensichtlich dass tom gelogen hat   \n",
       "196436             ist das ihr erster besuch dieser stadt   \n",
       "...                                                   ...   \n",
       "2742                                      ich bin beliebt   \n",
       "242060  das restaurant liegt auf der dem hotel gegenüb...   \n",
       "98885                tom hat seine autoschlüssel verloren   \n",
       "175799      ich glaube nicht dass sie französisch spricht   \n",
       "164527                 tom wusste dass er unersetzbar war   \n",
       "\n",
       "                                                   actual lstm_prediction  \\\n",
       "193956               you took it out of the oven too soon  to to to to to   \n",
       "40774                                  its freezing again                   \n",
       "214627          children should be allowed to be children        to to to   \n",
       "153323                     its obvious that tom was lying     to to to to   \n",
       "196436              is this your first visit to this town     to to to to   \n",
       "...                                                   ...             ...   \n",
       "2742                                           im popular                   \n",
       "242060  the restaurant is across the street from the h...  to to to to to   \n",
       "98885                           tom has lost his car keys                   \n",
       "175799                  i dont think she can speak french     to to to to   \n",
       "164527                    tom knew he couldnt be replaced     to to to to   \n",
       "\n",
       "                                      finetune_prediction  \n",
       "193956                you got it out of the oven too soon  \n",
       "40774                                    it freezes again  \n",
       "214627          children should be allowed to be children  \n",
       "153323                          its obvious that tom lied  \n",
       "196436              is this your first visit to this city  \n",
       "...                                                   ...  \n",
       "2742                                           im popular  \n",
       "242060  the restaurant is on the opposite side of the ...  \n",
       "98885                               tom lost his car keys  \n",
       "175799                     i dont think she speaks french  \n",
       "164527                      tom knew he was irreplaceable  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'input' : de_test, 'actual' : en_test, 'lstm_prediction' : lstm_prediction, 'finetune_prediction': predictions_niloo})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494d9c92-303f-447c-ad34-a390fc690d31",
   "metadata": {},
   "source": [
    "# Evaluating our models\n",
    "\n",
    "To evaluate the translation provided by the customized LSTM model and the fine-tuned model, we calculated the BLEU score for sentence pairs, meaning that we compare the output of a machine translation system to one or more human translations of the same input using this score.\n",
    "\n",
    "The similarity between machine-generated text and the reference translation is measured by counting how many n-grams (contiguous sequences of n words) in the machine-generated text appear in the reference translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8293addf-c5f4-41a3-a37c-fa9ee08557af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calc_bleu(ref, hyp):\n",
    "    ref = ref.split(\" \")\n",
    "    hyp = hyp.split(\" \")\n",
    "    score = sentence_bleu([ref], hyp)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cea594-f8c7-4251-9698-5e631510bf5e",
   "metadata": {},
   "source": [
    "Below, we compare the calculated BLEU score for the sentence pairs and the actual English sentence with the predicted translations. We see that our fine-tuned model performs much better than our current customized LSTM model, which can be further improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9349974-e984-4358-bae4-5b4470714464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/niloofar/.local/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>actual</th>\n",
       "      <th>lstm_prediction</th>\n",
       "      <th>bleu_lstm</th>\n",
       "      <th>bleu_finetune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193956</th>\n",
       "      <td>du hast es zu früh aus dem ofen geholt</td>\n",
       "      <td>you took it out of the oven too soon</td>\n",
       "      <td>to to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.506239e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40774</th>\n",
       "      <td>es friert wieder</td>\n",
       "      <td>its freezing again</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.384293e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214627</th>\n",
       "      <td>kinder sollten kind sein dürfen</td>\n",
       "      <td>children should be allowed to be children</td>\n",
       "      <td>to to to</td>\n",
       "      <td>3.648957e-232</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153323</th>\n",
       "      <td>es ist offensichtlich dass tom gelogen hat</td>\n",
       "      <td>its obvious that tom was lying</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.475183e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196436</th>\n",
       "      <td>ist das ihr erster besuch dieser stadt</td>\n",
       "      <td>is this your first visit to this town</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>4.739132e-232</td>\n",
       "      <td>8.408964e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217822</th>\n",
       "      <td>tom kann noch nicht gut flöte spielen</td>\n",
       "      <td>tom still isnt good at playing the flute</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.373704e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15019</th>\n",
       "      <td>tom glaubte mir</td>\n",
       "      <td>tom believed me</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190487</th>\n",
       "      <td>jetzt ist tom an der reihe fragen zu stellen</td>\n",
       "      <td>its now toms turn to ask questions</td>\n",
       "      <td>to to to to to to</td>\n",
       "      <td>9.853445e-232</td>\n",
       "      <td>4.335118e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203675</th>\n",
       "      <td>tom sieht überhaupt nicht wie ein lehrer aus</td>\n",
       "      <td>tom doesnt seem like a teacher at all</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.946036e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179020</th>\n",
       "      <td>tom hat herausgefunden wie man die kiste öffnet</td>\n",
       "      <td>tom discovered how to open the box</td>\n",
       "      <td>to to to to to</td>\n",
       "      <td>8.166727e-232</td>\n",
       "      <td>5.410823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149310</th>\n",
       "      <td>du brauchst nicht sarkastisch zu werden</td>\n",
       "      <td>you dont have to be sarcastic</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>7.813508e-232</td>\n",
       "      <td>9.013779e-155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142833</th>\n",
       "      <td>ich will nicht dass du da arbeitest</td>\n",
       "      <td>i dont want you working there</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.347209e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145256</th>\n",
       "      <td>sie hat zucker und salz verwechselt</td>\n",
       "      <td>she mistook the sugar for salt</td>\n",
       "      <td>to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.312766e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64343</th>\n",
       "      <td>er sang einige alte lieder</td>\n",
       "      <td>he sang some old songs</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>ist tom als nächster dran</td>\n",
       "      <td>is tom next</td>\n",
       "      <td>to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.221339e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62656</th>\n",
       "      <td>du machst es falsch</td>\n",
       "      <td>youre doing it wrong</td>\n",
       "      <td>to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165592</th>\n",
       "      <td>wir haben einige fragen an dich</td>\n",
       "      <td>weve got some questions for you</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.081327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192834</th>\n",
       "      <td>tom sollte mittlerweile schon gegessen haben</td>\n",
       "      <td>tom should have already eaten by now</td>\n",
       "      <td>to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.868092e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45766</th>\n",
       "      <td>haben sie diabetes</td>\n",
       "      <td>do you have diabetes</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30514</th>\n",
       "      <td>es ist alles vorbereitet</td>\n",
       "      <td>everythings ready</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.384293e-231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200272</th>\n",
       "      <td>gefällt dir der rahmen dieses gemäldes</td>\n",
       "      <td>do you like the frame on this painting</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.946036e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170476</th>\n",
       "      <td>sie ist ebenso schön wie ihre mutter</td>\n",
       "      <td>she is as beautiful as her mother</td>\n",
       "      <td>to to to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.133450e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180539</th>\n",
       "      <td>was reizte ihn ihr einen heiratsantrag zu machen</td>\n",
       "      <td>what tempted him to propose to her</td>\n",
       "      <td>to to to to to to</td>\n",
       "      <td>1.171779e-231</td>\n",
       "      <td>6.434589e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258945</th>\n",
       "      <td>tom konnte maria schon seit jahren gut leiden ...</td>\n",
       "      <td>tom liked mary for years but at some point his...</td>\n",
       "      <td>to to to to to to to to</td>\n",
       "      <td>3.985119e-232</td>\n",
       "      <td>4.444955e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232472</th>\n",
       "      <td>ich muss einkaufen gehen ich komme in einer st...</td>\n",
       "      <td>i have to go shopping ill be back in an hour</td>\n",
       "      <td>to to to to to to to</td>\n",
       "      <td>6.325073e-232</td>\n",
       "      <td>6.340466e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27008</th>\n",
       "      <td>das ist meine mutter</td>\n",
       "      <td>this is my mother</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33808</th>\n",
       "      <td>es ist etwas passiert</td>\n",
       "      <td>something happened</td>\n",
       "      <td></td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.491668e-154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166627</th>\n",
       "      <td>luft ist ein gemisch verschiedener gase</td>\n",
       "      <td>air is a mixture of several gases</td>\n",
       "      <td>to to</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.434589e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142494</th>\n",
       "      <td>ich habe mich dazu entschlossen stenographie z...</td>\n",
       "      <td>i decided to study stenography</td>\n",
       "      <td>to to to to to to</td>\n",
       "      <td>1.164047e-231</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114831</th>\n",
       "      <td>ich wollte nur helfen</td>\n",
       "      <td>i only wanted to be helpful</td>\n",
       "      <td>to to</td>\n",
       "      <td>2.073299e-232</td>\n",
       "      <td>1.384293e-231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "193956             du hast es zu früh aus dem ofen geholt   \n",
       "40774                                    es friert wieder   \n",
       "214627                    kinder sollten kind sein dürfen   \n",
       "153323         es ist offensichtlich dass tom gelogen hat   \n",
       "196436             ist das ihr erster besuch dieser stadt   \n",
       "217822              tom kann noch nicht gut flöte spielen   \n",
       "15019                                     tom glaubte mir   \n",
       "190487       jetzt ist tom an der reihe fragen zu stellen   \n",
       "203675       tom sieht überhaupt nicht wie ein lehrer aus   \n",
       "179020    tom hat herausgefunden wie man die kiste öffnet   \n",
       "149310            du brauchst nicht sarkastisch zu werden   \n",
       "142833                ich will nicht dass du da arbeitest   \n",
       "145256                sie hat zucker und salz verwechselt   \n",
       "64343                          er sang einige alte lieder   \n",
       "2790                            ist tom als nächster dran   \n",
       "62656                                 du machst es falsch   \n",
       "165592                    wir haben einige fragen an dich   \n",
       "192834       tom sollte mittlerweile schon gegessen haben   \n",
       "45766                                  haben sie diabetes   \n",
       "30514                            es ist alles vorbereitet   \n",
       "200272             gefällt dir der rahmen dieses gemäldes   \n",
       "170476               sie ist ebenso schön wie ihre mutter   \n",
       "180539   was reizte ihn ihr einen heiratsantrag zu machen   \n",
       "258945  tom konnte maria schon seit jahren gut leiden ...   \n",
       "232472  ich muss einkaufen gehen ich komme in einer st...   \n",
       "27008                                das ist meine mutter   \n",
       "33808                               es ist etwas passiert   \n",
       "166627            luft ist ein gemisch verschiedener gase   \n",
       "142494  ich habe mich dazu entschlossen stenographie z...   \n",
       "114831                              ich wollte nur helfen   \n",
       "\n",
       "                                                   actual  \\\n",
       "193956               you took it out of the oven too soon   \n",
       "40774                                  its freezing again   \n",
       "214627          children should be allowed to be children   \n",
       "153323                     its obvious that tom was lying   \n",
       "196436              is this your first visit to this town   \n",
       "217822           tom still isnt good at playing the flute   \n",
       "15019                                     tom believed me   \n",
       "190487                 its now toms turn to ask questions   \n",
       "203675              tom doesnt seem like a teacher at all   \n",
       "179020                 tom discovered how to open the box   \n",
       "149310                      you dont have to be sarcastic   \n",
       "142833                      i dont want you working there   \n",
       "145256                     she mistook the sugar for salt   \n",
       "64343                              he sang some old songs   \n",
       "2790                                          is tom next   \n",
       "62656                                youre doing it wrong   \n",
       "165592                    weve got some questions for you   \n",
       "192834               tom should have already eaten by now   \n",
       "45766                                do you have diabetes   \n",
       "30514                                   everythings ready   \n",
       "200272             do you like the frame on this painting   \n",
       "170476                  she is as beautiful as her mother   \n",
       "180539                 what tempted him to propose to her   \n",
       "258945  tom liked mary for years but at some point his...   \n",
       "232472       i have to go shopping ill be back in an hour   \n",
       "27008                                   this is my mother   \n",
       "33808                                  something happened   \n",
       "166627                  air is a mixture of several gases   \n",
       "142494                     i decided to study stenography   \n",
       "114831                        i only wanted to be helpful   \n",
       "\n",
       "                lstm_prediction      bleu_lstm  bleu_finetune  \n",
       "193956           to to to to to   0.000000e+00   7.506239e-01  \n",
       "40774                             0.000000e+00  1.384293e-231  \n",
       "214627                 to to to  3.648957e-232   1.000000e+00  \n",
       "153323              to to to to   0.000000e+00   5.475183e-01  \n",
       "196436              to to to to  4.739132e-232   8.408964e-01  \n",
       "217822              to to to to   0.000000e+00  6.373704e-155  \n",
       "15019                             0.000000e+00   1.221339e-77  \n",
       "190487        to to to to to to  9.853445e-232   4.335118e-78  \n",
       "203675              to to to to   0.000000e+00   5.946036e-01  \n",
       "179020           to to to to to  8.166727e-232   5.410823e-01  \n",
       "149310              to to to to  7.813508e-232  9.013779e-155  \n",
       "142833              to to to to   0.000000e+00   4.347209e-01  \n",
       "145256                    to to   0.000000e+00  1.312766e-231  \n",
       "64343               to to to to   0.000000e+00   1.000000e+00  \n",
       "2790                         to   0.000000e+00   1.221339e-77  \n",
       "62656                  to to to   0.000000e+00   1.000000e+00  \n",
       "165592              to to to to   0.000000e+00   5.081327e-01  \n",
       "192834                 to to to   0.000000e+00   6.868092e-78  \n",
       "45766                             0.000000e+00   1.000000e+00  \n",
       "30514                             0.000000e+00  1.384293e-231  \n",
       "200272              to to to to   0.000000e+00   5.946036e-01  \n",
       "170476              to to to to   0.000000e+00   5.133450e-01  \n",
       "180539        to to to to to to  1.171779e-231   6.434589e-01  \n",
       "258945  to to to to to to to to  3.985119e-232   4.444955e-78  \n",
       "232472     to to to to to to to  6.325073e-232   6.340466e-01  \n",
       "27008                             0.000000e+00   1.000000e+00  \n",
       "33808                             0.000000e+00  1.491668e-154  \n",
       "166627                    to to   0.000000e+00   6.434589e-01  \n",
       "142494        to to to to to to  1.164047e-231   1.000000e+00  \n",
       "114831                    to to  2.073299e-232  1.384293e-231  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"bleu_lstm\"] = pred_df.apply(lambda x: calc_bleu(x[\"actual\"], x[\"lstm_prediction\"]), axis=1)\n",
    "result[\"bleu_finetune\"] = pred_df.apply(lambda x: calc_bleu(x[\"actual\"], x[\"finetune_prediction\"]), axis=1)\n",
    "\n",
    "result.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a84e4-941b-4165-b8a1-c5ef21d5d06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
